            +----------------------+
            |        OS 211        |
            |  TASK 1: SCHEDULING  |
            |    DESIGN DOCUMENT   |
            +----------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Alessandro Bonardi ab9515@ic.ac.uk
Andy Hume ah2814@ic.ac.uk
Tanmay Khanna tk915@ic.ac.uk
Thomas Bower tb1215@ic.ac.uk

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, or notes for the
>> markers, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> A1: (5 marks)
>> Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

In thread.h, added following members to 'struct thread':

  int effective_priority;       - Effective Priority of the thread.
  struct list locks_held;       - List of currently held locks.
  struct lock *lock_to_acquire; - Lock currently acquired by another thread.

In synch.h, added the following member to 'struct lock':

  struct list_elem lock_elem;   - Shared with locks_held in struct thread.

>> A2: (10 marks)
>> Explain the data structure used to track priority donation.
>> Give a diagram that illustrates a nested donation in your structure.

TODO

---- ALGORITHMS ----

>> A3: (5 marks)
>> How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

>> A4: (5 marks)
>> Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

>> A5: (5 marks)
>> Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

---- SYNCHRONIZATION ----

>> A6: (5 marks)
>> Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

---- RATIONALE ----

>> A7: (5 marks)
>> Why did you choose this design?  In what ways is it superior to
>> another design you considered?

              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> B1: (5 marks)
>> Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

In newly added fixed-point.h, added the following typedef declaration:

  typedef int32_t fixed_point; - Type to represent a 17.14 fixed-point number.

In thread.h, added following members to 'struct thread':

  int nice;               - Nice value for the thread.
  fixed_point recent_cpu; - Estimate of CPU time used recently by the thread.

In thread.c, added following variables:

  static int ready_threads;                     - The number of threads ready
                                                  to run, cached to avoid
                                                  traversing the ready list
                                                  per load average computation.
  static fixed_point load_avg;                  - Estimates number of threads
                                                  to have run over the last
                                                  minute.
  static const fixed_point load_avg_factor;     - Constant factor (59/60) used
                                                  in load average calculation.
  static const fixed_point ready_thread_factor; - Constant factor (1/60) used
                                                  in load average calculation.
---- ALGORITHMS ----

>> B2: (5 marks)
>> Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0  63  61  59     A
 4      4   0   0  62  61  59     A
 8      8   0   0  61  61  59     A
12     12   0   0  60  61  59     B
16     12   4   0  60  60  59     A
20     16   4   0  59  60  59     B
24     16   8   0  59  59  59     A
28     20   8   0  58  59  59     B
32     20  12   0  58  58  59     C
36     20  12   4  58  58  58     A

>> B3: (5 marks)
>> Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behaviour of your scheduler?

Suppose we have a situation where the next thread ready to run has the same
priority as the currently running thread. The specification does not specify
whether the running thread should yield in this case.
  We resolve this ambiguity by the following rule. The running thread must
yield immediately if and only if the priority of the next ready thread is
strictly greater than the running thread's priority. This matches the behaviour
of our scheduler, as shown in our yield_if_higher_priority_ready() function.

>> B4: (5 marks)
>> How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

We update the BSD variables inside of thread_tick, which runs in an interrupt
context. This is undesirable, as we want to minimise the ammount of time we
spend inside interrupt handlers to improve responsiveness of the system and
avoid missing interrupts.
  We do take some steps to minimise this, such as keeping track of the number of
threads that are eligible to run in the static int ready_threads in thread.c,
which avoids traversing every element of the ready list in the interrupt
handler.
  Minimising the time spent in interrupt handlers gives better responsiveness
for interactive applications and keeps I/O devices busy.
  However, if we delegate the updating of the bsd variables to happen outside
of the interrupt handler, we will leave the ready list in an inconsistent state
(some threads will not have their priority updated based on up to date BSD
variables).

---- RATIONALE ----

>> B5: (5 marks)
>> Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.

Our implementation takes some steps to avoid doing unnecessary work.
  We only recalculate the priority for threads that are ready (rather than all
threads, as having fresh priority values for blocked threads is not necessary,
instead we recalculate values for blocked threads when they become unblocked.)
  Our use of macros to do fixed point arithmetic also eliminates a lot of
runtime overhead compared to if we used function calls.
  We also kept a number of threads that are ready to run (including the current
running thread, if it is not the idle thread). This is to avoid counting the
number of ready threads when we update load_avg in the interrupt handler.
  However, our implementation does a lot of the computation inside of an
interrupt context, which is a disadvantage for the reasons listed above.
  We considered implementing a lock on the ready list to get around this,
however we cannot acquire a lock from an interrupt context in thread_tick, and
if we updated the BSD variables in a separate thread which acquired the lock
outside of the interrupt, it may not run for a while and the BSD varaibles will
have outdated values.

>> B6: (5 marks)
>> The assignment explains arithmetic for fixed-point mathematics in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point mathematics, that is, an abstract
>> data type and/or a set of functions or macros to manipulate
>> fixed-point numbers, why did you do so?  If not, why not?S

For the fixed-point arithmetic we chose to create a new file in the threads
directory called fixed-point.h. In this file, we defined the 'fixed_point' type
to be an integer that represents a 17.14 fixed-point number, as well as the
fixed-point operations required by our scheduler.
  Due to the fact that we have to continuously update important fixed-point
values in the scheduler to calculate thread priorities, we chose to implement
these arithmetic operations in the form of macros rather than functions. Macros
are replaced by the pre-processor with the defined values, which meant there
was no unnecessary overhead at runtime from repeated calls.
